{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cognitive Decline Prediction Using EEG Data and Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Project Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project develops a machine learning classifier to distinguish between Alzheimer's Disease, Frontotemporal Dementia, and healthy controls using EEG signal features. The analysis follows a complete pipeline from data loading through model optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "from bids import BIDSLayout\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EEG Signal Preprocessing Pipeline\n",
    "The EEG recordings were exported in .eeg format and transformed to the BIDS-accepted .set format, with a preprocessing pipeline that included applying a Butterworth band-pass filter (0.5-45 Hz), re-referencing, and using Artifact Subspace Reconstruction (ASR) to remove bad data segments. Independent Component Analysis (ICA) was then performed to identify and reject components classified as eye or jaw artifacts, even though some eye movement artifacts remained in the resting state recordings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/derivatives\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Loading and Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load subject data\n",
    "def load_subject_data(subject_id):\n",
    "    subject_path = os.path.join(data_path, f\"sub-{subject_id:03d}\", \"eeg\", f\"sub-{subject_id:03d}_task-eyesclosed_eeg.set\")\n",
    "    # print(f\"Trying to load: {subject_path}\")  # Debugging line\n",
    "    raw = mne.io.read_raw_eeglab(subject_path, preload=True)  # Load the .set file\n",
    "    return raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def load_all_subjects(data_path, num_subjects=88):\n",
    "    raw_data_list = []\n",
    "    for subject_id in range(1, num_subjects + 1):\n",
    "        try:\n",
    "            raw = load_subject_data(subject_id)  # Load your EEG data here\n",
    "            raw_data_list.append(raw)\n",
    "            print(f\"Loaded data for subject {subject_id}\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Data for subject {subject_id} not found.\")\n",
    "    return raw_data_list'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''raw_data = load_subject_data(1)\n",
    "if raw_data is not None:\n",
    "    print(raw_data.info)  # Access the info attribute directly\n",
    "else:\n",
    "    print(\"No data was loaded.\")\n",
    "    \n",
    "raw_data.plot(n_channels=10, scalings='auto') # Test if data was loaded correctly'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load participant data\n",
    "participant_data_path = 'data/participants.tsv'\n",
    "participant_data = pd.read_csv(participant_data_path, sep='\\t')\n",
    "\n",
    "# Create a list to hold EEG data\n",
    "eeg_data_list = []\n",
    "\n",
    "# Load EEG data for each subject and store it in a list\n",
    "for subject_id in range(1, 89):  # Assuming 88 subjects\n",
    "    try:\n",
    "        raw = load_subject_data(subject_id)\n",
    "        eeg_data_list.append(raw)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Data for subject {subject_id} not found.\")\n",
    "\n",
    "# Create a DataFrame for EEG data\n",
    "eeg_df = pd.DataFrame({\n",
    "    'participant_id': [f'sub-{str(i).zfill(3)}' for i in range(1, 89)],\n",
    "    'eeg_data': eeg_data_list\n",
    "})\n",
    "\n",
    "# Check if all EEG data has been loaded\n",
    "print(f\"Loaded EEG data for {len(eeg_data_list)} subjects.\")\n",
    "\n",
    "# Merge EEG data with participant information\n",
    "combined_data = pd.merge(eeg_df, participant_data, on='participant_id')\n",
    "\n",
    "# Display summary of combined data instead of the entire DataFrame\n",
    "# For example, display the first few rows of participant information and EEG data shapes\n",
    "print(combined_data[['participant_id'] + list(participant_data.columns)])  # Adjust according to actual participant data columns\n",
    "\n",
    "# If you want to see the shape of the EEG data\n",
    "for index, row in combined_data.iterrows():\n",
    "    print(f\"{row['participant_id']} EEG data shape: {row['eeg_data'].get_data().shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Labels\n",
    "\n",
    "Encode the group labels into numerical format:\n",
    "Alzheimer's Disease (A) = 0\n",
    "Frontotemporal Dementia (F) = 1\n",
    "Healthy Control (C) = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_mapping = {'A': 0, 'F': 1, 'C': 2}\n",
    "combined_data['Group'] = combined_data['Group'].map(group_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the combined data to a CSV file\n",
    "output_csv_path = 'data/combined_eeg_participant_data.csv'\n",
    "combined_data.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"Combined data saved to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Feature Extraction Functions\n",
    "\n",
    "Let's define functions to extract relevant features from your EEG data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bandpower Extraction \n",
    "\n",
    "Analyze how different frequency bands (delta, theta, alpha, beta, gamma) change across different brain regions (channels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_bandpower(raw, freq_bands, n_fft=2048):\n",
    "    \"\"\"Extract bandpower features from EEG data.\"\"\"\n",
    "    # Compute the Power Spectral Density (PSD)\n",
    "    spectrum = raw.compute_psd(method='welch', n_fft=n_fft)\n",
    "    psd_data, freqs = spectrum.get_data(return_freqs=True)\n",
    "\n",
    "    bandpowers = {}\n",
    "    for band, (fmin, fmax) in freq_bands.items():\n",
    "        # Find the indices of frequencies within the specified band\n",
    "        band_idx = np.where((freqs >= fmin) & (freqs <= fmax))[0]\n",
    "        # Average the PSD values over the band\n",
    "        bandpower = np.mean(psd_data[:, band_idx], axis=1)  # Average across all frequencies in the band\n",
    "        bandpowers[band] = bandpower\n",
    "\n",
    "    return bandpowers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Indices of Frequencies and Initialize Feature Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_bands = {\n",
    "    'delta': (0.5, 4),\n",
    "    'theta': (4, 8),\n",
    "    'alpha': (8, 13),\n",
    "    'beta': (12, 25),\n",
    "    'gamma': (25, 45)\n",
    "}\n",
    "\n",
    "# Create a list to hold the feature dictionaries\n",
    "features_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power Spectral Density (PSD)\n",
    "\n",
    "Using the Welch method is a technique for estimating the power of a signal's frequency components. It provides a way to analyze the distribution of power across different frequencies in a signal, making it useful for identifying dominant frequency components in various applications such as EEG analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute band power for different frequency bands per channel\n",
    "def compute_bandpower_per_channel(raw, freq_range):\n",
    "    # Compute the power spectral density using Welch's method\n",
    "    spectrum = raw.compute_psd(method=\"welch\")\n",
    "    # Retrieve the power spectral density data and corresponding frequencies\n",
    "    data, freqs = spectrum.get_data(return_freqs=True)\n",
    "\n",
    "    # Find indices of the frequency range\n",
    "    freq_indices = np.logical_and(freqs >= freq_range[0], freqs <= freq_range[1])\n",
    "    # Compute the average power in the desired frequency band for each channel\n",
    "    band_power = np.mean(data[:, freq_indices], axis=1)  # Average power for each channel\n",
    "    \n",
    "    return band_power"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connectivity Measures\n",
    "\n",
    "Connectivity measures are useful for assessing interactions between different EEG channels or brain regions. Correlation measures linear dependency between signals from different channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute connectivity between EEG channels\n",
    "def compute_connectivity(raw):\n",
    "    \"\"\"\n",
    "    Computes the functional connectivity using correlation between channels.\n",
    "    \n",
    "    Parameters:\n",
    "        raw: MNE Raw object containing the EEG data.\n",
    "        \n",
    "    Returns:\n",
    "        Connectivity matrix (correlation coefficients).\n",
    "    \"\"\"\n",
    "    data = raw.get_data()  # Get all channels, shape (n_channels, n_samples)\n",
    "    connectivity_matrix = np.corrcoef(data)  # Calculate correlation coefficients\n",
    "    return connectivity_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Extract Features and Append to Feature Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list.clear() #Ensure we reset our feeatures_list\n",
    "# Iterate over the rows in combined_data\n",
    "for index, row in combined_data.iterrows():\n",
    "    raw = row['eeg_data']  # Get the raw EEG data\n",
    "    bandpower_results = {}\n",
    "\n",
    "    # Calculate band power for each frequency band for each channel\n",
    "    for band, freq_range in freq_bands.items():\n",
    "        bandpower_results[band] = compute_bandpower_per_channel(raw, freq_range)\n",
    "\n",
    "    # Create a feature dictionary\n",
    "    features = {\n",
    "        'participant_id': row['participant_id'],\n",
    "        'Gender': row['Gender'],\n",
    "        'Age': row['Age'],\n",
    "        'Group': row['Group'],\n",
    "        'MMSE': row['MMSE']\n",
    "    }\n",
    "\n",
    "    # Add bandpower features for each channel\n",
    "    for band, power in bandpower_results.items():\n",
    "        # Assuming you have 'n_channels' number of channels\n",
    "        for i, channel_power in enumerate(power):\n",
    "            features[f'bandpower_{band}_channel_{i+1}'] = channel_power  # +1 for human-readable indexing\n",
    "        features[f'average_bandpower_{band}'] = np.mean(power)\n",
    "\n",
    "    # Calculate and add connectivity features\n",
    "    connectivity_matrix = compute_connectivity(raw)\n",
    "    \n",
    "    # For simplicity, you can extract average connectivity or specific values\n",
    "    features['average_connectivity'] = np.mean(connectivity_matrix)  # Average connectivity across channels\n",
    "\n",
    "    # Example: Add specific channel correlations if desired\n",
    "    # features['connectivity_1_2'] = connectivity_matrix[0, 1]  # Correlation between channel 1 and channel 2\n",
    "\n",
    "    features_list.append(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame for features\n",
    "features_df = pd.DataFrame(features_list)\n",
    "\n",
    "# Display the features DataFrame\n",
    "print(features_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save features to a CSV file\n",
    "features_df.to_csv('data/extracted_features.csv', index=False)\n",
    "print(\"Extracted features saved to extracted_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display descriptive statistics\n",
    "print(features_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization \n",
    "\n",
    "Visually compare the distribution of various bandpower features among different groups of participants using a correlation matrix. We will use the plot to determine which channel recordings and frequency types correlate with our patient groupings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features_df = features_df.select_dtypes(include=[np.number])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = numeric_features_df.corr()\n",
    "\n",
    "correlation_matrix.to_csv('data/correlation_matrix_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Extract correlations with \"Group\" and drop self-correlation\n",
    "group_correlation = correlation_matrix['Group'].drop('Group')  # Drop self-correlation\n",
    "\n",
    "group_correlation .to_csv('data/group_correlation _df.csv', index=False)\n",
    "# Step 3: Get absolute values of the correlations\n",
    "absolute_group_correlation = group_correlation.abs()\n",
    "\n",
    "# Step 4: Sort the absolute correlations in descending order\n",
    "sorted_group_correlation = absolute_group_correlation.sort_values(ascending=False)\n",
    "\n",
    "# Display the sorted correlations\n",
    "print(sorted_group_correlation[:21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the columns to drop (for both bandpower_gamma and bandpower_beta, plus Age and MMSE)\n",
    "columns_to_drop = ['Age', 'MMSE']\n",
    "\n",
    "# Drop the specified columns and rows from the correlation matrix\n",
    "filtered_corr_matrix = correlation_matrix.drop(columns=columns_to_drop)\n",
    "\n",
    "# Drop the same rows to keep the matrix symmetric\n",
    "filtered_corr_matrix = filtered_corr_matrix.drop(index=columns_to_drop)\n",
    "\n",
    "# Plot the filtered correlation matrix\n",
    "plt.figure(figsize=(75, 75))\n",
    "sns.heatmap(filtered_corr_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', square=True)\n",
    "plt.title('Correlation Matrix of Features')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We care about 'Group' correlation in our matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming correlation_matrix is already defined\n",
    "# Define the columns to drop (for both bandpower_gamma and bandpower_beta, plus Age and MMSE)\n",
    "columns_to_drop = ['Age', 'MMSE', 'Group']\n",
    "\n",
    "# Drop the specified columns to create a filtered correlation matrix\n",
    "filtered_corr_matrix = correlation_matrix.drop(columns=columns_to_drop)\n",
    "\n",
    "# Select only the \"Group\" row from the filtered correlation matrix\n",
    "group_corr_matrix = filtered_corr_matrix.loc[['Group']]\n",
    "\n",
    "# Plot the correlation matrix for \"Group\" only\n",
    "plt.figure(figsize=(75, 50))  # Adjust the figure size as needed\n",
    "sns.heatmap(group_corr_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', square=True, cbar=False)\n",
    "plt.title('Correlation of Features with Group')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relevant Feature Extraction\n",
    "\n",
    "This way, we will only train our model using the top features that provide the highest accuracy.\n",
    "\n",
    "According to the literature, AD patients exhibit changes in the RBP such as reduced alpha power and increased theta power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Extract the top 19 feature names, excluding MMSE\n",
    "top_features = sorted_group_correlation.index[:21].tolist()\n",
    "\n",
    "# Step 2: Remove MMSE if it's in the top features\n",
    "top_features = [feature for feature in top_features if feature != 'MMSE'] # We only want to use EEG\n",
    "\n",
    "# Step 3: Format the list to match your desired output\n",
    "feature_columns = [f\"{feature}\" for feature in top_features]\n",
    "\n",
    "# Print the feature columns in the desired format\n",
    "formatted_feature_columns = ',\\n    '.join(feature_columns)\n",
    "formatted_output = f\"feature_columns = [\\n    {formatted_feature_columns}\\n]\"\n",
    "\n",
    "print(formatted_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split  dataset into training and testing subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Select features and target variable\n",
    "X = features_df[feature_columns]  # Features with selected columns\n",
    "y = features_df['Group']           # Target variable (you can change this based on your analysis)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.35, random_state=42)\n",
    "\n",
    "# Optional: Print the shapes of the training and testing sets to confirm\n",
    "print(f\"X_train shape: {X_train.shape}, X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}, y_test shape: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nðŸ“ Saving train/test splits to CSV files...\")\n",
    "\n",
    "# Create a directory for the splits (optional)\n",
    "output_dir = \"train_test_splits\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    print(f\"Created directory: {output_dir}\")\n",
    "\n",
    "# Save training features\n",
    "X_train.to_csv(f\"{output_dir}/X_train.csv\", index=False)\n",
    "print(f\"âœ… Saved X_train to {output_dir}/X_train.csv\")\n",
    "\n",
    "# Save test features  \n",
    "X_test.to_csv(f\"{output_dir}/X_test.csv\", index=False)\n",
    "print(f\"âœ… Saved X_test to {output_dir}/X_test.csv\")\n",
    "\n",
    "# Save training labels\n",
    "pd.Series(y_train, name='Group').to_csv(f\"{output_dir}/y_train.csv\", index=False)\n",
    "print(f\"âœ… Saved y_train to {output_dir}/y_train.csv\")\n",
    "\n",
    "# Save test labels\n",
    "pd.Series(y_test, name='Group').to_csv(f\"{output_dir}/y_test.csv\", index=False)\n",
    "print(f\"âœ… Saved y_test to {output_dir}/y_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved data\n",
    "X_train = pd.read_csv(\"train_test_splits/X_train.csv\")\n",
    "X_test = pd.read_csv(\"train_test_splits/X_test.csv\")  # Fixed: was X_train.csv\n",
    "y_train = pd.read_csv(\"train_test_splits/y_train.csv\").iloc[:, 0]  # Fixed: was X_train.csv\n",
    "y_test = pd.read_csv(\"train_test_splits/y_test.csv\").iloc[:, 0]    # Fixed: was X_train.csv\n",
    "\n",
    "print(\"Data loaded successfully!\")\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")\n",
    "print(f\"Original class distribution:\")\n",
    "print(y_train.value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE, ADASYN, BorderlineSMOTE, SVMSMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler, TomekLinks\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "\n",
    "# Dictionary of resampling techniques to test\n",
    "resampling_techniques = {\n",
    "    'Original (No Resampling)': None,\n",
    "    'SMOTE': SMOTE(random_state=42),\n",
    "    'ADASYN': ADASYN(random_state=42),\n",
    "    'Borderline SMOTE': BorderlineSMOTE(random_state=42, kind='borderline-1'),\n",
    "    'SVM SMOTE': SVMSMOTE(random_state=42),\n",
    "    'Random Undersampling': RandomUnderSampler(random_state=42),\n",
    "    'Tomek Links': TomekLinks(),\n",
    "    'SMOTE + ENN': SMOTEENN(random_state=42),\n",
    "    'SMOTE + Tomek': SMOTETomek(random_state=42)\n",
    "}\n",
    "\n",
    "print(f\"Will test {len(resampling_techniques)} different techniques\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "def quick_evaluate_resampling(X_train_res, y_train_res, technique_name):\n",
    "    \"\"\"Quick evaluation with basic XGBoost parameters\"\"\"\n",
    "    model = XGBClassifier(\n",
    "        learning_rate=0.1,\n",
    "        max_depth=2,\n",
    "        n_estimators=200,\n",
    "        random_state=42,\n",
    "        objective='multi:softmax',\n",
    "        verbosity=0\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train_res, y_train_res)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "print(\"Quick evaluation function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store results for comparison\n",
    "resampling_results = {}\n",
    "resampled_datasets = {}\n",
    "\n",
    "print(\"Testing resampling techniques...\\n\" + \"=\"*60)\n",
    "\n",
    "for technique_name, resampler in resampling_techniques.items():\n",
    "    print(f\"\\nTesting: {technique_name}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    try:\n",
    "        # Apply resampling\n",
    "        if resampler is None:\n",
    "            X_train_res, y_train_res = X_train.copy(), y_train.copy()\n",
    "            print(\"Using original data distribution\")\n",
    "        else:\n",
    "            X_train_res, y_train_res = resampler.fit_resample(X_train, y_train)\n",
    "            print(f\"Resampled data distribution:\")\n",
    "        \n",
    "        # Show class distribution\n",
    "        class_counts = pd.Series(y_train_res).value_counts().sort_index()\n",
    "        print(class_counts)\n",
    "        print(f\"Total samples: {len(y_train_res)}\")\n",
    "        \n",
    "        # Quick evaluation\n",
    "        accuracy = quick_evaluate_resampling(X_train_res, y_train_res, technique_name)\n",
    "        \n",
    "        # Store results\n",
    "        resampling_results[technique_name] = {\n",
    "            'accuracy': accuracy,\n",
    "            'total_samples': len(y_train_res),\n",
    "            'class_distribution': class_counts.to_dict()\n",
    "        }\n",
    "        \n",
    "        # Store best datasets for later use\n",
    "        resampled_datasets[technique_name] = (X_train_res, y_train_res)\n",
    "        \n",
    "        print(f\"Quick test accuracy: {accuracy:.3f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error with {technique_name}: {str(e)}\")\n",
    "        continue\n",
    "    \n",
    "    print(\"-\" * 40)\n",
    "\n",
    "print(f\"\\nCompleted testing {len(resampling_results)} techniques\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results summary\n",
    "results_df = pd.DataFrame(resampling_results).T\n",
    "results_df = results_df.sort_values('accuracy', ascending=False)\n",
    "\n",
    "print(\"RESAMPLING TECHNIQUE COMPARISON\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"{'Technique':<25} {'Accuracy':<10} {'Samples':<10}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for technique, row in results_df.iterrows():\n",
    "    print(f\"{technique:<25} {row['accuracy']:<10.3f} {row['total_samples']:<10}\")\n",
    "\n",
    "print(\"\\nTop 3 techniques:\")\n",
    "top_3 = results_df.head(3).index.tolist()\n",
    "for i, technique in enumerate(top_3, 1):\n",
    "    accuracy = results_df.loc[technique, 'accuracy']\n",
    "    print(f\"{i}. {technique}: {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically select the best technique\n",
    "best_technique = results_df.index[0]  # Top performer\n",
    "best_accuracy = results_df.iloc[0]['accuracy']\n",
    "\n",
    "print(f\"Best resampling technique: {best_technique}\")\n",
    "print(f\"Best quick test accuracy: {best_accuracy:.3f}\")\n",
    "\n",
    "# Get the best resampled dataset\n",
    "X_train_resampled, y_train_resampled = resampled_datasets[best_technique]\n",
    "\n",
    "print(f\"\\nFinal resampled training set:\")\n",
    "print(f\"Shape: {X_train_resampled.shape}\")\n",
    "print(f\"Class distribution:\")\n",
    "print(pd.Series(y_train_resampled).value_counts().sort_index())\n",
    "\n",
    "# Save the best resampled data (optional)\n",
    "# pd.DataFrame(X_train_resampled).to_csv(\"X_train_resampled_best.csv\", index=False)\n",
    "# pd.Series(y_train_resampled).to_csv(\"y_train_resampled_best.csv\", index=False)\n",
    "\n",
    "print(f\"\\nReady for hyperparameter tuning with {best_technique}!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "print(\"Libraries loaded for manual hyperparameter tuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_params = {\n",
    "    'learning_rate': 0.1,        # Lower learning rate for better generalization\n",
    "    'max_depth': 2,               # Shallow trees to prevent overfitting\n",
    "    'n_estimators': 200,          # Moderate number of trees\n",
    "    'subsample': 0.9,             # Use 90% of samples for each tree\n",
    "    'colsample_bytree': 0.9,      # Use 90% of features for each tree\n",
    "    'reg_alpha': 0,              # L1 regularization\n",
    "    'reg_lambda': 5,             # L2 regularization\n",
    "    'gamma': 1,                   # Minimum loss reduction required\n",
    "    'min_child_weight': 1         # Minimum samples in leaf\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating XGBoost model with manual parameters...\")\n",
    "\n",
    "# Create model with manual parameters\n",
    "xgb_model = XGBClassifier(\n",
    "    **manual_params,\n",
    "    random_state=42,\n",
    "    eval_metric='logloss',\n",
    "    use_label_encoder=False\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "print(\"Training model...\")\n",
    "start_time = time.time()\n",
    "xgb_model.fit(X_train_resampled, y_train_resampled)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Training completed in {(end_time - start_time):.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "# Evaluate with cross-validation\n",
    "print(\"Evaluating with cross-validation...\")\n",
    "cv_strategy = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(xgb_model, X_train_resampled, y_train_resampled, \n",
    "                           cv=cv_strategy, scoring='accuracy')\n",
    "\n",
    "print(\"CROSS-VALIDATION RESULTS\")\n",
    "print(\"=\" * 30)\n",
    "print(f\"CV Scores: {cv_scores}\")\n",
    "print(f\"Mean CV Score: {cv_scores.mean():.4f}\")\n",
    "print(f\"Std CV Score: {cv_scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test set\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"TEST SET EVALUATION\")\n",
    "print(\"=\" * 30)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"CV Score: {cv_scores.mean():.4f}\")\n",
    "print(f\"Difference: {abs(test_accuracy - cv_scores.mean()):.4f}\")\n",
    "\n",
    "if abs(test_accuracy - cv_scores.mean()) > 0.05:\n",
    "    print(\"Large difference between CV and test scores - possible overfitting\")\n",
    "else:\n",
    "    print(\"Good generalization - CV and test scores are close\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nDETAILED CLASSIFICATION REPORT\")\n",
    "print(\"=\" * 50)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"CONFUSION MATRIX\")\n",
    "print(\"-\" * 20)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "# Per-class accuracy\n",
    "print(\"\\nPER-CLASS ACCURACY\")\n",
    "print(\"-\" * 25)\n",
    "for i in range(len(np.unique(y_test))):\n",
    "    if i < len(cm):\n",
    "        class_accuracy = cm[i, i] / cm[i, :].sum() if cm[i, :].sum() > 0 else 0\n",
    "        print(f\"Class {i}: {class_accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import learning_curve\n",
    "# Plot learning curves to visualize overfitting\n",
    "def plot_learning_curves(model, X, y, cv=5):\n",
    "    \"\"\"Plot learning curves to detect overfitting\"\"\"\n",
    "    \n",
    "    train_sizes, train_scores, val_scores = learning_curve(\n",
    "        model, X, y, cv=cv, n_jobs=-1,\n",
    "        train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "        scoring='accuracy'\n",
    "    )\n",
    "    \n",
    "    train_mean = np.mean(train_scores, axis=1)\n",
    "    train_std = np.std(train_scores, axis=1)\n",
    "    val_mean = np.mean(val_scores, axis=1)\n",
    "    val_std = np.std(val_scores, axis=1)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_sizes, train_mean, 'o-', color='blue', label='Training Accuracy')\n",
    "    plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1, color='blue')\n",
    "    \n",
    "    plt.plot(train_sizes, val_mean, 'o-', color='red', label='Validation Accuracy')\n",
    "    plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, alpha=0.1, color='red')\n",
    "    \n",
    "    plt.xlabel('Training Set Size')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Learning Curves')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "    # Analysis\n",
    "    final_gap = train_mean[-1] - val_mean[-1]\n",
    "    print(f\"Final gap between training and validation: {final_gap:.3f}\")\n",
    "    if final_gap > 0.1:\n",
    "        print(\"Strong evidence of overfitting\")\n",
    "    elif final_gap > 0.05:\n",
    "        print(\"Moderate overfitting\")\n",
    "    else:\n",
    "        print(\"Good generalization\")\n",
    "\n",
    "# Run learning curve analysis\n",
    "print(\"Generating learning curves...\")\n",
    "plot_learning_curves(xgb_model, X_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get feature importance\n",
    "feature_importance = xgb_model.feature_importances_\n",
    "feature_names = X_train.columns if hasattr(X_train, 'columns') else [f'Feature_{i}' for i in range(len(feature_importance))]\n",
    "\n",
    "# Create feature importance DataFrame\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': feature_importance\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"TOP 20 MOST IMPORTANT FEATURES\")\n",
    "print(\"=\" * 40)\n",
    "print(importance_df.head(10))\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_features = importance_df.head(10)\n",
    "plt.barh(range(len(top_features)), top_features['importance'])\n",
    "plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Top 10 Feature Importances (XGBoost)')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary classification: Disease vs Healthy\n",
    "print(\"Creating binary classification: Disease vs Healthy\")\n",
    "\n",
    "# Combine classes 0 and 1 as \"Disease\", class 2 as \"Healthy\"\n",
    "y_binary = (y == 2).astype(int)  # 1 = Healthy, 0 = Disease\n",
    "\n",
    "print(\"Binary class distribution:\")\n",
    "print(f\"Disease (0): {sum(y_binary == 0)} samples\")\n",
    "print(f\"Healthy (1): {sum(y_binary == 1)} samples\")\n",
    "\n",
    "# Split data\n",
    "X_train_bin, X_test_bin, y_train_bin, y_test_bin = train_test_split(\n",
    "    X, y_binary, test_size=0.3, stratify=y_binary, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set: Disease={sum(y_train_bin == 0)}, Healthy={sum(y_train_bin == 1)}\")\n",
    "print(f\"Test set: Disease={sum(y_test_bin == 0)}, Healthy={sum(y_test_bin == 1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_eeg_discriminative_features(X_train, X_test, y_train):\n",
    "    \"\"\"Create EEG features specifically for class discrimination\"\"\"\n",
    "    \n",
    "    X_train_new = X_train.copy()\n",
    "    X_test_new = X_test.copy()\n",
    "    \n",
    "    # 1. FREQUENCY BAND RATIOS (important for EEG classification)\n",
    "    print(\"Creating frequency band ratios...\")\n",
    "    \n",
    "    # Alpha/Beta ratio (cognitive load indicator)\n",
    "    alpha_cols = [col for col in X_train.columns if 'alpha' in col and 'channel' in col]\n",
    "    beta_cols = [col for col in X_train.columns if 'beta' in col and 'channel' in col]\n",
    "    \n",
    "    if alpha_cols and beta_cols:\n",
    "        X_train_new['alpha_beta_ratio_mean'] = X_train[alpha_cols].mean(axis=1) / (X_train[beta_cols].mean(axis=1) + 1e-8)\n",
    "        X_test_new['alpha_beta_ratio_mean'] = X_test[alpha_cols].mean(axis=1) / (X_test[beta_cols].mean(axis=1) + 1e-8)\n",
    "        \n",
    "        # Channel-specific alpha/beta ratios for important channels\n",
    "        for i, (alpha_col, beta_col) in enumerate(zip(alpha_cols[:5], beta_cols[:5])):  # Top 5 channels\n",
    "            ratio_name = f'alpha_beta_ratio_ch_{i+1}'\n",
    "            X_train_new[ratio_name] = X_train[alpha_col] / (X_train[beta_col] + 1e-8)\n",
    "            X_test_new[ratio_name] = X_test[alpha_col] / (X_test[beta_col] + 1e-8)\n",
    "    \n",
    "    # 2. HEMISPHERIC ASYMMETRY (left vs right brain activity)\n",
    "    print(\"Creating hemispheric asymmetry features...\")\n",
    "    \n",
    "    # Assuming standard EEG channel layout - adjust channel numbers based on your setup\n",
    "    left_channels = [7, 9, 10]  # Example left hemisphere channels\n",
    "    right_channels = [15, 16, 19]  # Example right hemisphere channels\n",
    "    \n",
    "    for band in ['alpha', 'beta']:\n",
    "        left_cols = [col for col in X_train.columns if band in col and any(f'channel_{ch}' in col for ch in left_channels)]\n",
    "        right_cols = [col for col in X_train.columns if band in col and any(f'channel_{ch}' in col for ch in right_channels)]\n",
    "        \n",
    "        if left_cols and right_cols:\n",
    "            left_mean_train = X_train[left_cols].mean(axis=1)\n",
    "            right_mean_train = X_train[right_cols].mean(axis=1)\n",
    "            left_mean_test = X_test[left_cols].mean(axis=1)\n",
    "            right_mean_test = X_test[right_cols].mean(axis=1)\n",
    "            \n",
    "            # Asymmetry index: (Left - Right) / (Left + Right)\n",
    "            X_train_new[f'{band}_asymmetry'] = (left_mean_train - right_mean_train) / (left_mean_train + right_mean_train + 1e-8)\n",
    "            X_test_new[f'{band}_asymmetry'] = (left_mean_test - right_mean_test) / (left_mean_test + right_mean_test + 1e-8)\n",
    "    \n",
    "    # 3. CLASS-SPECIFIC FEATURES (simplified)\n",
    "    print(\"Creating class-discriminative features...\")\n",
    "    \n",
    "    # Find features with highest between-class variance\n",
    "    from sklearn.feature_selection import f_classif\n",
    "    f_scores, _ = f_classif(X_train, y_train)\n",
    "    top_discriminative_features = X_train.columns[np.argsort(f_scores)[-3:]]  # Top 3 to avoid too many features\n",
    "    \n",
    "    print(f\"Most discriminative original features: {list(top_discriminative_features)}\")\n",
    "    \n",
    "    # Create simple ratio features from top discriminative features\n",
    "    for i, feat1 in enumerate(top_discriminative_features):\n",
    "        for feat2 in top_discriminative_features[i+1:]:\n",
    "            ratio_name = f'{feat1}_div_{feat2}'.replace('bandpower_', '').replace('channel_', 'ch')[:30]  # Shorten names\n",
    "            X_train_new[ratio_name] = X_train[feat1] / (X_train[feat2] + 1e-8)\n",
    "            X_test_new[ratio_name] = X_test[feat1] / (X_test[feat2] + 1e-8)\n",
    "    \n",
    "    return X_train_new, X_test_new\n",
    "\n",
    "# Apply feature engineering to binary classification\n",
    "print(\"Applying feature engineering to binary classification...\")\n",
    "X_train_bin_eng, X_test_bin_eng = create_eeg_discriminative_features(\n",
    "    X_train_bin, X_test_bin, y_train_bin\n",
    ")\n",
    "\n",
    "print(f\"Original features: {X_train_bin.shape[1]}\")\n",
    "print(f\"After engineering: {X_train_bin_eng.shape[1]}\")\n",
    "print(f\"New features added: {X_train_bin_eng.shape[1] - X_train_bin.shape[1]}\")\n",
    "\n",
    "# Apply feature selection\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "selector_binary = SelectKBest(score_func=f_classif, k=25)  # Select top 25 features\n",
    "X_train_bin_selected = selector_binary.fit_transform(X_train_bin_eng, y_train_bin)\n",
    "X_test_bin_selected = selector_binary.transform(X_test_bin_eng)  # Fixed: use X_test_bin_eng\n",
    "\n",
    "# Get selected feature names\n",
    "selected_feature_names = X_train_bin_eng.columns[selector_binary.get_support()]\n",
    "print(f\"Selected {len(selected_feature_names)} best features for binary classification\")\n",
    "\n",
    "# Create final DataFrames without index issues\n",
    "X_train_bin_final = pd.DataFrame(X_train_bin_selected, columns=selected_feature_names)\n",
    "X_test_bin_final = pd.DataFrame(X_test_bin_selected, columns=selected_feature_names)\n",
    "\n",
    "print(f\"Final binary feature set shapes:\")\n",
    "print(f\"Training: {X_train_bin_final.shape}\")\n",
    "print(f\"Test: {X_test_bin_final.shape}\")\n",
    "print(\"Feature engineering for binary classification completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Apply SMOTE for binary classification\n",
    "print(\"Applying SMOTE to binary classification...\")\n",
    "smote_binary = SMOTE(random_state=42)\n",
    "X_train_bin_resampled, y_train_bin_resampled = smote_binary.fit_resample(\n",
    "    X_train_bin_final, y_train_bin\n",
    ")\n",
    "\n",
    "print(\"Binary class distribution after SMOTE:\")\n",
    "print(f\"Disease (0): {sum(y_train_bin_resampled == 0)}\")\n",
    "print(f\"Healthy (1): {sum(y_train_bin_resampled == 1)}\")\n",
    "\n",
    "# Train binary XGBoost\n",
    "print(\"Training binary XGBoost model...\")\n",
    "xgb_binary = XGBClassifier(\n",
    "    learning_rate=0.1,\n",
    "    max_depth=3,\n",
    "    n_estimators=200,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_alpha=10,\n",
    "    reg_lambda=20,\n",
    "    random_state=42,\n",
    "    eval_metric='logloss',\n",
    "    use_label_encoder=False\n",
    ")\n",
    "\n",
    "xgb_binary.fit(X_train_bin_resampled, y_train_bin_resampled)\n",
    "\n",
    "# Evaluate binary model\n",
    "y_pred_binary = xgb_binary.predict(X_test_bin_final)\n",
    "accuracy_binary = accuracy_score(y_test_bin, y_pred_binary)\n",
    "\n",
    "print(f\"\\nBINARY CLASSIFICATION RESULTS:\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Accuracy: {accuracy_binary:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_bin, y_pred_binary, \n",
    "                          target_names=['Disease', 'Healthy']))\n",
    "\n",
    "# Confusion matrix\n",
    "cm_binary = confusion_matrix(y_test_bin, y_pred_binary)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(\"Predicted:  Disease  Healthy\")\n",
    "print(f\"Disease:      {cm_binary[0,0]:3d}      {cm_binary[0,1]:3d}\")\n",
    "print(f\"Healthy:      {cm_binary[1,0]:3d}      {cm_binary[1,1]:3d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify performance with CV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cv_scores_binary = cross_val_score(xgb_binary, X_train_bin_resampled, y_train_bin_resampled, cv=5)\n",
    "print(f\"Binary CV Scores: {cv_scores_binary}\")\n",
    "print(f\"Mean CV Score: {cv_scores_binary.mean():.4f} (Â±{cv_scores_binary.std():.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We can conclude from our hyperparameter tuning that despite potentially achieving higher F1 scores, this would lead to overfitting as our model's performance on the test data remains poor. \n",
    "\n",
    "If we perform cross-validation accross our original data set, we get an average CV score of 65%. \n",
    "\n",
    "Our model is able to determine whether or not our subject is healthy or not, but struggles when determining whether they have AD or Dementia."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
